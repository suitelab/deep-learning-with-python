{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 훈련, 검증, 테스트 세트로 나누는 이유는 훈련에 사용하는 데이터로 모델을 평가하게 되면 **오버피팅**이 일어나기 쉽기 때문이다.  \n",
    "오버피팅이 일어나면 훈련 데이터에 대한 성능은 좋아지지만 새로운 데이터에 대한 성능이 좋아지지 않거나 나빠진다.  \n",
    "\n",
    "또한 훈련, 테스트 단 두개만 이용하지 않는 이유는 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문이다.  \n",
    "예를들어 layer의 수나 layer의 유닛 수같은 **하이퍼파라미터(hyperparameter)** 선택한다.  \n",
    "\n",
    "본질적으로 이런 튜닝도 어떤 파라미터 공간에서 좋은 설정을 찾는 **학습**이다.  \n",
    "결국 검증 세트로 직접 훈련하지 않더라도 빠르게 **검증세트에 오버피팅** 될 수 있다.\n",
    "\n",
    "이러한 현상이 일어나는건 **정보 누설(information leak)** 개념 때문이다.  \n",
    "검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것이다.  \n",
    "결국 검증 세트로 여러차례 모델을 조정하게 되면 검증세트에 아주 잘 작동하게 된다.  \n",
    "모델을 평가하기 위해서는 완전히 이전에 본 적 없는 다른 데이터 셋(테스트 세트)을 사용해야한다.\n",
    "\n",
    "데이터를 훈련, 검증, 테스트 세트로 나누는 것은 간단해 보일 수 있지만 데이터가 적을 때는 몇가지 고급 기법을 사용하면 도움이 된다.\n",
    "대표적으로  \n",
    "- 단순 홀드아웃 검증(hold-out validation)\n",
    "- K-겹 교차 검증(K-fold cross-validation)\n",
    "- 셔플링을 사용한 반복 K-겹 교차 검증(iterated K-fold cross-validation)\n",
    "\n",
    "의 세가지 기법이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순 홀드아웃 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 일정량을 테스트 세트로 떼어 놓고, 남은 데이터에서 다시 훈련 세트와 검증세트로 나누어 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_sample = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# 모델 튜닝, 훈련, 평가, 튜닝 ...\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,\n",
    "                           validation_data]))\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
